#=
Running inference simulations with `Model3SP` and
`HybridGrowthRateModel`, for data generated by `Model3SPStar` (time
varying `r` model) with different `s` values.

Inference simulations are ran in a distributed fashion; the first argument to
the script corresponds to the number of processes used.

```
julia scripts/inference_3sp/inference_3sp.jl 10
```
will run the script over 10 processes.
=#
cd(@__DIR__)
using JLD2
using DataFrames
using Random
using Dates
using ProgressMeter
using ComponentArrays
import OrdinaryDiffEq: Tsit5
using PiecewiseInference
include("../../src/utils.jl")
include("../../src/hybrid_model_2.jl")
include("../../src/3sp_model.jl")
include("../../src/loss_fn.jl")

const Epochs = [5000]
const TrueParameters = ComponentArray(H = Float32[1.24, 2.5],
                            q = Float32[4.98, 0.8],
                            r = Float32[1.0, -0.4, -0.08],
                            A = Float32[1.0])
const TrueInitialState = Float32[0.77, 0.060, 0.945]
const TimeSteps = range(500f0, step=4, length=100)
const TimeSpan = (0f0, TimeSteps[end])
const loss_likelihood = LossLikelihood()

Random.seed!(5)

# TODO: to modify for a struct, see Flux.jl example zoo
function generate_model_params()
    return (alg = Tsit5(),
            abstol = 1e-4,
            reltol = 1e-4,
            tspan = TimeSpan,
            saveat = TimeSteps,
            verbose = false,
            maxiters = 50_000)
end

function generate_data()
    model_params = generate_model_params()
    model = Model3SP(ModelParams(; u0=TrueInitialState, model_params...))
    return simulate(model, p = TrueParameters ) |> Array
end

function initialize_params_and_constraints(model::HybridFuncRespModel)
    p_true = model.mp.p
    T = eltype(p_true)
    distrib_param_arr = Pair{Symbol, Any}[]

    for dp in keys(p_true)
        pair = dp => Product([Uniform(sort(T[0.25 * k, 1.75 * k])...) for k in p_true[dp]])
        push!(distrib_param_arr, pair)
    end
    pair_r = :r => Product([Uniform(sort(T[0.25 * k, 1.75 * k])...) for k in p_true.r[2:end]])
    pair_nn = :p_nn => Uniform(-Inf, Inf)
    append!(distrib_param_arr, [pair_r, pair_nn])


    distrib_param = NamedTuple(distrib_param_arr)
    p_bij = NamedTuple([dp => bijector(distrib_param[dp]) for dp in keys(distrib_param)])
    u0_bij = bijector(Uniform(T(1e-3), T(5e0)))  # For initial conditions
    p_init = NamedTuple([k => rand(distrib_param[k]) for k in keys(distrib_param)])
    p_nn, _ = Lux.setup(rng, neural_net)
    p_init = merge(p_init, (;p_nn))

    return ComponentArray(p_init), p_bij, u0_bij
end

# TODO: create a struct with *training* meta parameters
function create_simulation_parameters(data)
    group_sizes = [11]
    # noises = 0.1:0.1:0.3
    noises = [0.1]
    nruns = 1
    adtypes = [Optimization.AutoZygote()]

    pars_arr = []
    for group_size in group_sizes, noise in noises, run in 1:nruns, adtype in adtypes
        sensealg = typeof(adtype) <: AutoZygote ? BacksolveAdjoint(autojacvec=ReverseDiffVJP(true)) : nothing
        model_params = generate_model_params()

        u0_init = data[:,1]

        # Hybrid model
        model = HybridFuncRespModel(ModelParams(; p=p_true, u0=u0_init, sensealg, model_params...))
        p_init, p_bij, u0_bij = initialize_params_and_constraints(model)
        infprob = InferenceProblem(model, p_init; 
                                    loss_u0_prior = loss_likelihood, 
                                    loss_likelihood = loss_likelihood, 
                                    p_bij, u0_bij)

        sim_params = (;group_size, noise, adtype, model, d, infprob, pref)
        push!(pars_arr, sim_params)

    end
    return pars_arr
end

data = generate_data()
simulation_parameters = create_simulation_parameters(data);

println("Starting simulations...")
stats = @timed inference(infprob; group_size = group_size,
                        data = data_w_noise, 
                        adtype, epochs, inference_params...)

res = stats.value
l = res.losses[end]

